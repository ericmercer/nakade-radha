\section{Related Work}

Different parallel programming models have been created with different properties such as task interactions, task granularity,  etc. Some examples of these models are message passing, data parallelism, task parallelism. Message passing \cite{Forum:1994:MMI:898758} programs create multiple tasks with each encapsulating some local data. Data is shared between the tasks by sending messages from one task to another. MPICH is a widely used implementation of the MPI protocol. Data parallelism refers to application of same instruction to multiple elements of data. Task parallelism is achieved by executing different instructions concurrently on multiple sets of data.

In this research we are mainly going to focus on task parallel programs. Various task parallel languages have been developed such as Habanero Java, Cilk, X10, Chapel, OpenMP 3.0 etc. Habanero Java \cite{cave2011habanero} is a task parallel programming language developed at the Rice University. It was developed as an extension to X10 with particular emphasis on safety properties of parallel constructs. The HJ compiler generates standard Java class files that can run on any JVM. The HJ runtime is responsible for orchestrating the creation, execution and termination of HJ tasks. A Java 8 implementation for this language, known as HJLib \cite{imam2014habanero} has also been created. This library makes extensive use of lambda expressions and can run on any Java 8 JVM. HJ programs provide various safety guarantees if the parallel programming constructs are used correctly. Verifying HJ programs using tools such as Java Path Finder (JPF) can be time and memory consuming because of the numerous JPF state expansions. Hence, an HJ verification runtime (VR) \cite{anderson2014jpf} was developed at Brigham Young University to use JPF for verifying HJ programs. This runtime provides a lightweight alternative to verifying HJ programs using JPF.

X10 \cite{charles2005x10} was developed at IBM as a part of the IBM PERCS project (Productive Easy-to-use Reliable Computer Systems). X10 is a type-safe, parallel, distributed object oriented language with support for high performance computation over distributed multi-dimensional arrays. Gligoric et al. extended the model checker JPF in \cite{gligoric2012x10x} to verify X10 programs and detect concurrency related bugs. Chapel programming language \cite{chamberlain2007parallel} was developed as a part of DARPA's High Productivity Computing Systems (HPCS) program. Chapel provides higher-level abstractions for parallelism using anonymous threads that are implemented by compiler and runtime system. Chapel programs are subject to concurrency problems such as deadlocks, race conditions etc. To verify the correctness of chapel programs, Zirkel et al. developed a tool for model checking and symbolic execution of chapel programs \cite{zirkel2013automated}.

Model checking suffers from an inherent shortcoming. The exponential growth in the state space of the program being verified makes model checking unsuitable for large programs. A lot of methods are being developed such as partial order reductions that help to reduce the state space that needs to be explored for finding bugs such as data races which can be detected only under certain thread interleavings. Also, some errors are dependent on the control flow structure of the program. These errors are detected only if a given input takes that particular branch of the branch on which the error exists. To detect such errors we have test on all the branches on the program. Concolic execution provides a way of detecting errors on all possible branches of the program. Concolic execution automates test input generation by combining the concrete and symbolic execution of the code under test. Concolic execution couples both concrete and symbolic execution by running both of them simultaneously such that each gets feedback from the other.

Sen and Agha developed a concolic execution tool called CUTE in \cite{sen2006cute} for testing programs written in C and Java. The tool consists of two modules: an instrumentation module and library to perform symbolic execution. The instrumentation module inserts code in the program to call the library at runtime for performing symbolic execution. Another concolic execution tool for Java programs was developed by Jayaraman et al. in \cite{jayaraman2009jfuzz}. This tool is called jFUZZ. It is a concolic white box fuzzer built on top of Java Path Finder(JPF). Starting from a seed input, jFUZZ automatically generates inputs that explore new program paths. Sen et al. developed a tool called DART (Directed Automated Random Testing) to automatically test softwares \cite{godefroid2005dart} . It combines three techniques: automated extraction of the interface of a program with its external environment using static source-code parsing; automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. DART has been implemented to test programs written in C.

Task parallel languages achieve parallelism by distributing execution processes across different parallel computing nodes. A formal model can be used to describe the properties of task parallel programming languages. 
\\
\\
\textbf{Semantics of parallel programming languages:}
Creating semantic models of programming languages helps to reason about the properties and performance of the various constructs of programming languages. This is an important step in the verification process of programming languages.

Emmi and Boujjani introduced an interleaving free model of isolated hierarchical parallel computations for expressing general parallel programming languages \cite{bouajjani2012analysis}. They formalized a system for measuring the complexity of deciding state reachability for finite-data recursive programs. Another way of creating formal models of programming languages is through Redex \cite{klein2012run}. Redex is an executable domain-specific language for mechanizing semantic models developed by PLT. These models can be used to state theorems about the models and prove them. Redex is used by semantics engineers to formulate the syntax and semantics of the model, create test suites, run randomized testing and use graphical tools for visualizing examples etc.

Formal definitions of various properties of programming languages are also very important for the verification process.
\\
\\
\textbf{Formalism of properties of Parallel Programming languages:}

Scott and Lu have proposed various history-based definitions of determinism in \cite{lu2011toward}. They have discussed the comparative advantages of these defined properties. They have also discussed the containment relationships for these properties.

Dennis, Gao and Sarkar presented precise definitions of the two related properties of program schemata – ‘determinacy’ and ‘repeatability’ in \cite{dennis2012determinacy}. A key advantage of providing definitions for schemata rather than concrete programs is that it simplifies the task for programmers and tools to check these properties. The definitions of these properties are provided for schemata arising from data flow programs and task-parallel programs, thereby also establishing new relationships between the two models.

Race conditions occur in shared-memory parallel programs when accesses to shared-memory are not synchronized. Netzer and Miller formalized the definitions of  race conditions occurring in shared-memory parallel programs \cite{netzer1992race}. The race conditions are divided broadly into two categories - general races that cause deterministic programs to fail in execution and data races that appear in non-deterministic programs.

Banerjee et al. developed a rigorous mathematical framework that can be used to study the trade-off between the amount of access history kept and the kinds of data races that can be detected \cite{banerjee2006theory}. Using this framework, they developed some algorithms for data race detection under different conditions.

Bocchino et al. developed a region-based type and effect system for expressing important patterns of deterministic parallelism in imperative, object-oriented programs \cite{bocchino2009type}. This system simplifies parallel programming by guaranteeing deterministic semantics with modular, compile time type checking.

Kahlon and Wang proposed a concept of Universal Causality Graphs (UCG) in \cite{kahlon2010universal}. UCGs encode the set of all feasible interleavings that a given correctness property may violate. UCGs provide a unified happens-before model by capturing causality constraints imposed by the property at hand as well as scheduling constraints imposed by synchronization primitives as causality constraints.

Using these formal definitions of various properties, various tools were developed for data-race detection, deadlock detection, checking determinism etc.\\
\\
\textbf{Checking Determinism: }

In a parallel program, the threads of the parallel program can be interleaved non-deterministically during execution. Different thread interleavings result in different outputs for the same program input. Some of the results produced by such interleavings can be correct while others are wrong. Parallel programs should always produce the correct result irrespective of the thread interleavings that occur during program execution.

Burnim and Sen created an assertion framework that can be used to specify pairs of program state that can arise due to non-deterministic thread inter-leavings\cite{burnim2009asserting}. Such pairs of program state result in a deterministic result in spite of the different parallel schedules. They created a Java library that can be used to specify these assertions. They also created an algorithm called Determin \cite{burnim2010determin} that can dynamically infer likely deterministic specification when provided with a set of inputs and schedules

Insta-check \cite{nistor2010instantcheck} is another technique for checking external determinism during testing of parallel programs. It checks whether different runs of a parallel program with same input produce different outputs. This is done by computing a 64-bit hash of the memory state during program run. If two program runs with same input produce different hashes, then insta-check reports that the program is non-deterministic. 

Vechev et al. developed a static analysis technique for automatic verification of determinism in parallel programs \cite{vechev2011automatic}. The analysis is done in two phases. First phase identifies parts of the parallel program that run in parallel. Each part is sequentially analyzed by assuming that all memory locations accessed by the task are independent from locations accessed by other tasks that are running in parallel. In the second phase, the analysis checks whether this independence assumption holds i.e. all memory accesses are independent.

The main cause of non-determinism in parallel programs is data races and deadlocks that arise during different schedules of the program. To prove program correctness of parallel programs, it is important to detect all data races and deadlocks.
\\
\\
\textbf{Data Race and Deadlock Detection: }

Data races occur in parallel programs when two or more threads access a memory location and at least one of the accesses is a ‘write’.  It is very difficult to detect data races in concurrent programs. Deadlocks cause the programs to stall. A number of researchers have worked on data race and deadlock detection.

Savage et al. developed a tool called Eraser \cite{savage1997eraser} to dynamically detect data races in multi-threaded programs. Eraser uses binary rewriting techniques to monitor every shared-memory reference and verify that consistent locking behavior is used.

A method to perform static data race detection in concurrent C programs was developed by Kahlon et al. This method \cite{kahlon2009static} involved creating a precise context-sensitive concurrent control flow graph. Using this graph, identify the shared variables and lock pointers, compute on initial database of race warnings and then prune away the spurious messages using may-happen-in-parallel (MHP) analysis.

Flanagan and Freund developed a precise data race detection tool called FastTrack \cite{flanagan2009fasttrack}. It uses an adaptive lightweight representation for the happens-before relation that reduces both time and space overheads.

Engler and Aashcraft developed a static tool called RacerX for detection of deadlocks and race conditions \cite{engler2003racerx}. The tool is specifically designed for checking large multi-threaded systems. It has been applied to Linux, FreeBSD etc. for detecting concurrency related errors in these complex systems. 