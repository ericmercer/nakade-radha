\section{Project Description}
\subsection{High Level Description}
Task parallel programming languages execute different processes on multiple computing cores. Processes execute different instructions simultaneously leading to different thread schedules and memory access patterns. To test the correctness of the program, all possible thread-interleavings have to be considered. The control flow of the program also has to be considered while checking program correctness. Errors are sometimes only detected when the program executed a particular branch of code. Such type of errors are dependent on the input and the control flow of the program. A computation graph of a task parallel program helps to visualize the execution of the program for particular input. As the input of the program changes, the shape of the computation graph can change if the program follows a different path of execution. Enumerating all inputs that cause the program to take all possible paths is a way to create all possible computation graph structures. Concolic execution of a program (executing program both symbolically and concretely) is a way enumerate all possible inputs of the program that create different computation graph structures.
\subsection{Computation Graphs}
The execution of an task parallel program can be represented in the form of a computation graph. A computation graph of a program is a directed acyclic graph(DAG) structure that captures the meaning of the program's execution as a partial order. A computation graph consists of:
\begin{enumerate}
\item A set of nodes, where each node represents a step consisting of an arbitrary sequential computation. 
\item A set of directed edges that represent ordering constraints. 
\begin{itemize}
 \item Spawn edges that connect steps in parent tasks to steps in child async tasks. When an async is created, a spawn edge is inserted between the step that ends with the async in the parent task and the step that starts the async body in the new child task.
\item Join edges that connect steps in descendant tasks to steps in the tasks containing their Immediately Enclosing Finish (IEF) instances. When an async terminates, a join edge is inserted from the last step in the async to the step that follows the IEF operation in the task containing the IEF operation.
\item Continue edges that capture sequencing of steps within a a task - all steps within the same task are connected by a chain of continue edges.
 \end{itemize} 
\end{enumerate}

\subsection{Properties of Task Parallel Programs}
The following properties of task parallel programs can be verified using computation graphs.
\subsubsection{Determinism}
Determinism refers to obtaining the same result from a parallel program for a given input. There are different definitions that determine the degree of determinism in parallel programs.
\begin{enumerate}
\item
\textbf{External (or functional) determinism:\\}
External determinism requires the parallel program to produce the same output when run on the same input. Programs executions for a given input may be different, but they ultimately produce the same output.
\item
\textbf{Internal (or structural) determinism:\\}
This type of determinism requires the parallel program to not only produce the same output for a given input, but also to produce a unique computation graph for a given input.
\end{enumerate}
\subsubsection{Deadlock}
A Deadlock arises in parallel programs when two or more processes are waiting to acquire resources held by other processes without making any progress. The necessary conditions (known as the Coffman conditions) for a deadlock to arise are as follows:
\begin{enumerate}
\item 
{Mutual Exclusion:} At least one resource must be held in a non-shareable mode. Only one process can access the resource at any given time. 
\item
{Hold and Wait:} This condition refers to a process holding a non shareable resource and trying to acquire another one.
\item
{No Preemption}
If no tasks are allowed to preempt other tasks from holding the locks for certain resources, it can cause a deadlock to happen.
\item
{Circular Wait} Circular wait implies that there are at least two tasks that are waiting on resources held by the other tasks.
\end{enumerate}

A computation graph keeps track of all the resources being accessed or requested by processes. If there is a circular dependency for any of the resources in the graph, then a deadlock is reported.

\subsubsection{Data Race}
Data races occur in parallel programs when two or more tasks try to access shared variables such that at least one of the accesses is a 'write'. Data races cause the output of the program to become non-deterministic. Data races can be detected in a computation graph when two parallel nodes in the graph access a memory location and atleast one of the operations tries to modify it.
