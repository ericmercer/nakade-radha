\section{Project Description}
The research described here proposes a new technique for verification of task parallel programs with the help of computation graphs. It uses Habanero Java as an exemplar of task parallel languages. Habanero Java language is a task parallel programming language built as an extension to X10 language. It includes a set of powerful parallel programming constructs that can be used to create programs that are inherently safe. HJ programs can be run on any JVM including Java 8 JVM.  The Habanero Java language puts particular emphasis on the usability and safety of parallel programming constructs. For Example, no HJ program written using async, finish, isolated and phaser constructs can create a logical deadlock cycle.

\subsection{Background Information}

\subsubsection{HJ constructs}
Habanero Java consists of a wide range of constructs for parallel programming.
\begin{enumerate}
\item \textbf{Task Spawn and Join} - Async and finish constructs are used to create and join tasks created by a parent process. The statement async(() $ \rightarrow \langle$stmt$\rangle$) creates a new task that can logically execute in parallel with its parent task. The Finish method is used to represent join in Habanero Java. The task executing finish(() $ \rightarrow \langle$stmt$\rangle$) has to wait for all the tasks running inside stmt to finish before it can move on.
\item \textbf{Loop Parallelism} - The forall and foreach constructs in HJ are used for loop parallelism. An implicit finish is included at the end of forall iterations whereas foreach iterations do not have an implicit finish. 
\item \textbf{Coordination Constructs} - There are often dependencies among parallel tasks. To coordinate the execution of the parallel tasks, Habanero Java provides some constructs such as isolated, futures, data-driven futures and phasers.
\begin{enumerate}
\item \textbf{Isolated} - Most of the concurrently running processes have the need to synchronize the access to the shared variables. The isolated statements allow only one process at a time to access referenced shared variables. Isolated statements create performance bottlenecks in moderate to high contention systems. HJ also provides object-based isolation which provides better performance.
\item \textbf{Futures} - HJ supports returning values from a newly created child task to the parent task with the help of futures. The statement HjFuture$\langle$T$\rangle$ f = future $\langle$T$\rangle$ (() $ \rightarrow \langle$expr$\rangle$) creates a new child task which executes expr and the result of this execution can be obtained by the parent task by calling f.get() method.
\item \textbf{Data-driven futures} - DDFs are an extension to futures. Any async can register on a DDF as a consumer causing the execution of the async to be delayed until a value becomes available in the DDF. The exact syntax for an async waiting on a DDF is as follows: asyncAwait(ddf1, ... , ddfN, () $\rightarrow$ stmt). An async waiting on a chain of DDFs can only begin executing after a put() has been invoked on all the DDFs.
\item \textbf{Phasers} - Phasers help in point-to-point synchronization. Each task has the option of registering with a phaser in signal-only/wait-only mode for producer/consumer synchronization or signal-wait mode for barrier synchronization. A task may be registered on multiple phasers, and a phaser may have multiple tasks registered on it. Phasers ensure deadlock freedom when programmers use only the next statements in their programs. In programs where tasks are involved with multiple point-to-point coordination, explicit use of doWait() and doSignal() on multiple phasers might be required.  
\end{enumerate}
\end{enumerate}

\subsubsection{Computation Graphs}
The execution of an task parallel program can be represented in the form of a computation graph. A computation graph of a program is a directed acyclic graph(DAG) structure that represents the sequence of execution of tasks in the parallel program. A computation graph can be represented as G = $\langle$V, E$\rangle$ where
\begin{itemize}
\item V represents a set of nodes such that  each node represents a step consisting of an arbitrary sequential computation and
\item E represents a set of directed edges that represent ordering constraints. The various types of edges in a computation graph are:
\begin{enumerate}
 \item \textbf{Spawn edges} - They connect steps in parent tasks to steps in child async tasks. When an async is created, a spawn edge is inserted between the step that ends with the async in the parent task and the step that starts the async body in the new child task.
\item \textbf{Join edges} - They connect steps in descendant tasks to steps in the tasks containing their Immediately Enclosing Finish (IEF) instances. When an async terminates, a join edge is inserted from the last step in the async to the step that follows the IEF operation in the task containing the IEF operation.
\item \textbf{Continue edges} - They capture sequencing of steps within a task - all steps within the same task are connected by a chain of continue edges.
\item \textbf{Serialization edges} - They connect two isolated nodes S and S' where nodes S and S' are interfering. Two isolated nodes do not interfere only if they have a total ordering in the CG.
 \end{enumerate} 
\end{itemize}

\subsubsection{HJ example with its computation graph representation}
Fig.1 shows an example program written in Habanero Java. In this example, the main process starts two new processes running in parallel with the process. The main process has to stop its execution at the end of finish block and wait for the child processes to complete their execution before the main process can proceed further. This results in a computation graph shown in fig. 2. 

\begin{figure}[h!]
\centering
\begin{minipage}[b]{0.35\linewidth}
    \includegraphics[scale=0.3]{../figs/Fig1.jpg} 
\caption{Example HJ Program}
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[b]{0.35\linewidth}
\includegraphics[scale=0.3]{../figs/Fig2.jpg}
\caption{Computation Graph of the example program}
\label{fig:minipage2}
\end{minipage}
\end{figure}

\subsubsection{Properties of Task Parallel Programs}
The following properties of task parallel programs can be verified using computation graphs.

\begin{enumerate}
\item
\textbf{Data Race:}
Data races occur in parallel programs when two or more tasks try to access shared variables such that at least one of the accesses is a 'write'. Data races cause the output of the program to become non-deterministic. 
\item
\textbf{Determinism:}
Determinism refers to obtaining the same result from a parallel program for a given input. There are different definitions that determine the degree of determinism in parallel programs.
\begin{enumerate}
\item
\textbf{Internal (or structural) determinism:\\}
This type of determinism requires the parallel program to not only produce the same output for a given input, but also to produce a unique computation graph for a given input. A program is internally deterministic only if it is free of data-races.
\item
\textbf{External (or functional) determinism:\\}
External determinism requires the parallel program to produce the same output when run on the same input. Program's executions for a given input may be different, but they ultimately produce the same output. In the presence of data-races, a program is externally deterministic if every pair of concurrent operators commute.
\end{enumerate}
\end{enumerate}

\subsection{Implementation details}
An HJ computation graph can be built using a tool called HJ-Viz. HJ-Viz processes the event logs produced by the HJLib runtime and generates a dot representation of the computation graph. The dot file can later be processed and displayed in the user's web browser using the HJ-Viz server. The drawback of this tool is that it does not store the computation graph in a logical data structure that can be traversed and analyzed to verify the properties of the program. Another drawback is that it does not save any memory references to objects. Hence, we need to create a tool that can build a computation graph of an HJ program during runtime and store the information in a logical data-structure that is easy to traverse and analyze.

The modified computation graph builder is implemented using Java Path Finder(JPF). It uses the Verification Runtime, specifically designed to run HJ programs using JPF. The HJ program is compiled using the VR and the class files are analyzed using JPF. JPF creates thread choice generators to systematically explore the state-space of the programs. We use one choice of thread interleavings at a time to observe the execution and build a computation graph for this execution. The VM listeners in JPF are extended to track the thread creations, executions, joins etc. Memory references are also registered in the computation graphs. The computation graphs are stored in DAG data structure. We are going to use jgrapht library that provides an implementation of this data structure.

Data races can be detected in a computation graph when two parallel nodes in the graph access a memory location and atleast one of the operations tries to modify it. A Topological traversal of the graph gives the order of execution of the various tasks. All the nodes that occur between  a pair of Finish-start and Finish-end nodes execute in parallel. The global memory accesses by these processes have to be checked and if conflicting memory-accesses are observed, then a data race should be reported.

For checking functional determinism of the program in the presence of data-races, JPF schedules on the memory location access that is part of the data race. If all the executions of the program produce the same result, then the program is functionally deterministic.

In programs with isolated regions (CG containing serialization edges), JPF creates schedules such that all possible orderings between the interfering isolated nodes is considered. The rest of the process for detecting data-races and checking determinism is carried out on all the obtained computation graphs.

\subsection{Other Task Parallel Languages}
This proposal uses Habanero Java language to describe the implementation details. Using the semantic model for parallel programming languages described in \cite{bouajjani2012analysis}, it can be shown that Habanero Java is a superset of other task parallel languages. It contains a wide range of parallel programming constructs that can be used to perform all operations that are possible in other task parallel languages such that Cilk, Chapel, OpenMP3.0, X10 etc. In this section, we describe how to create computation graphs for other task parallel languages. The analysis of these computation graphs can be done in the same way as computation graphs for Habanero Java programs. The following examples illustrate the computation graphs for programs written in different task parallel languages.

\begin{enumerate}
\item 
\textbf{X10}
\begin{figure}[H]
\centering
\begin{minipage}[b]{0.35\linewidth}
    \includegraphics[scale=0.4]{../figs/X10.jpg} 
\caption{X10 Program}
\label{fig:minipage3}
\end{minipage}
\quad
\begin{minipage}[b]{0.35\linewidth}
\includegraphics[scale=0.2]{../figs/X10_CG.jpg}
\caption{CG of X10 Program}
\label{fig:minipage4}
\end{minipage}
\end{figure}

\item
\textbf{OpenMP3.0}
\begin{figure}[H]
\centering
\begin{minipage}[b]{0.35\linewidth}
    \includegraphics[scale=0.2]{../figs/Openmp.jpg} 
\caption{Openmp Program}
\label{fig:minipage5}
\end{minipage}
\quad
\begin{minipage}[b]{0.35\linewidth}
\includegraphics[scale=0.1]{../figs/openmp_CG.jpg}
\caption{CG of Openmp Program}
\label{fig:minipage6}
\end{minipage}
\end{figure}

\item
\textbf{Cilk}
\begin{figure}[H]
\centering
\begin{minipage}[b]{0.35\linewidth}
    \includegraphics[scale=0.2]{../figs/Cilk.jpg} 
\caption{Cilk Program}
\label{fig:minipage7}
\end{minipage}
\quad
\begin{minipage}[b]{0.35\linewidth}
\includegraphics[scale=0.1]{../figs/Cilk_CG.jpg}
\caption{CG of Cilk Program}
\label{fig:minipage8}
\end{minipage}
\end{figure}

\item
\textbf{Chapel}
\begin{figure}[H]
\centering
\begin{minipage}[b]{0.35\linewidth}
    \includegraphics[scale=0.2]{../figs/Chapel.jpg} 
\caption{Chapel Program}
\label{fig:minipage9}
\end{minipage}
\quad
\begin{minipage}[b]{0.35\linewidth}
\includegraphics[scale=0.1]{../figs/Chapel_CG.jpg}
\caption{CG of Chapel Program}
\label{fig:minipage10}
\end{minipage}
\end{figure}

\end{enumerate}